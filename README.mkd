# CS50 AI - Coursework Repository

This repository showcases my work from the **CS50 Introduction to Artificial Intelligence** course.  
It contains implementations and projects covering various AI concepts, divided by class modules.

---

## Search

- **Degrees**: Implements a breadth-first search to determine the shortest path between two actors through their shared movies.  
- **Knight**: Solves the problem of finding the shortest path a knight can take on a chessboard using search algorithms.

## Knowledge

- **Minesweeper**: A logical AI agent that plays Minesweeper by inferring safe moves and mine locations.  
- **TicTacToe**: Implements an AI agent using the Minimax algorithm to play Tic-Tac-Toe optimally.

---

## Uncertainty

- **PageRank**: Models and ranks nodes on a graph according to their relative importance, foundational for search engine algorithms and probabilistic reasoning.
- **Heredity**: Looks into probabilistic models for heredity/genetics, applying Bayesian inference and uncertain knowledge representation.

---

## Optimization

- **Crossword**: Uses constraint satisfaction and backtracking algorithms to fill crossword puzzles, demonstrating optimization and search in combinatorial spaces.

---

## Learning

- **Shopping**: A supervised learning project using K-nearest neighbors (KNN) applying machine learning techniques to consumer data.
- **Nim**: Implements a Q-learning agent to play the Nim game, utilizing reinforcement learning techniques like Q-value updates and epsilon-greedy action selection for game playing and policy learning.

---

## Neural Networks

- **Traffic**: The Traffic project uses a convolutional neural network (CNN) to classify German traffic sign images from the GTSRB dataset. The model takes resized sign images as input and predicts their type, demonstrating practical deep learning for visual classification

---

## Language

- **Parser**: The Parser project implements a context-free grammar using NLTK to parse English sentences and extract noun phrases. It identifies sentence structure and finds all minimal noun phrase chunks for information extraction, demonstrating syntactic analysis in natural language processing.


- **Attntion**: The Attention project uses BERT and the transformers library to predict masked words in text and visualize attention scores from all self-attention heads. It demonstrates how transformer-based models leverage context and internal attention mechanisms to understand and process natural language.

